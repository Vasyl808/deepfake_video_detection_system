{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10760425,
          "sourceType": "datasetVersion",
          "datasetId": 6674682
        },
        {
          "sourceId": 10807207,
          "sourceType": "datasetVersion",
          "datasetId": 6708346
        },
        {
          "sourceId": 10807236,
          "sourceType": "datasetVersion",
          "datasetId": 6708367
        },
        {
          "sourceId": 173391,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 147600,
          "modelId": 170127
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 39039.177908,
      "end_time": "2025-02-28T06:21:24.278854",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-02-27T19:30:45.100946",
      "version": "2.6.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    },
    "colab": {
      "name": "notebook42e9a5f248",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "vasylhunia_stepdata20_path = kagglehub.dataset_download('vasylhunia/stepdata20')\n",
        "vasylhunia_dfdc20frames_path = kagglehub.dataset_download('vasylhunia/dfdc20frames')\n",
        "vasylhunia_deepfakeseqdataset10dir_path = kagglehub.dataset_download('vasylhunia/deepfakeseqdataset10dir')\n",
        "vasylhunia_resnet50x4_pytorch_default_1_path = kagglehub.model_download('vasylhunia/resnet50x4/PyTorch/default/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "8cB9fCf1SVuP"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet_pytorch --no-deps"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:09.985429Z",
          "iopub.execute_input": "2025-02-28T17:58:09.985716Z",
          "iopub.status.idle": "2025-02-28T17:58:11.796265Z",
          "shell.execute_reply.started": "2025-02-28T17:58:09.985683Z",
          "shell.execute_reply": "2025-02-28T17:58:11.795259Z"
        },
        "papermill": {
          "duration": 1.658892,
          "end_time": "2025-02-27T19:30:49.389788",
          "exception": false,
          "start_time": "2025-02-27T19:30:47.730896",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "WezRb4bCSVuW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/kaggle/input/dfdc20frames/'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:11.797198Z",
          "iopub.execute_input": "2025-02-28T17:58:11.797539Z",
          "iopub.status.idle": "2025-02-28T17:58:11.801918Z",
          "shell.execute_reply.started": "2025-02-28T17:58:11.797506Z",
          "shell.execute_reply": "2025-02-28T17:58:11.800916Z"
        },
        "papermill": {
          "duration": 0.014823,
          "end_time": "2025-02-27T19:30:49.414631",
          "exception": false,
          "start_time": "2025-02-27T19:30:49.399808",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "LRxAVLqgSVuY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import datetime\n",
        "import sys\n",
        "import itertools\n",
        "import os.path\n",
        "import time\n",
        "import glob\n",
        "import subprocess\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "import gc\n",
        "import math\n",
        "from typing import List, Dict, Tuple, Union\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from facenet_pytorch import MTCNN\n",
        "from torch.nn import functional\n",
        "import torchvision.models as models\n",
        "import cv2\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:11.802948Z",
          "iopub.execute_input": "2025-02-28T17:58:11.803239Z",
          "iopub.status.idle": "2025-02-28T17:58:19.276814Z",
          "shell.execute_reply.started": "2025-02-28T17:58:11.803213Z",
          "shell.execute_reply": "2025-02-28T17:58:19.276159Z"
        },
        "papermill": {
          "duration": 9.879756,
          "end_time": "2025-02-27T19:30:59.303561",
          "exception": false,
          "start_time": "2025-02-27T19:30:49.423805",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "kAYdGgyeSVuY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:19.27924Z",
          "iopub.execute_input": "2025-02-28T17:58:19.279608Z",
          "iopub.status.idle": "2025-02-28T17:58:19.349521Z",
          "shell.execute_reply.started": "2025-02-28T17:58:19.279589Z",
          "shell.execute_reply": "2025-02-28T17:58:19.3485Z"
        },
        "papermill": {
          "duration": 0.066021,
          "end_time": "2025-02-27T19:30:59.379135",
          "exception": false,
          "start_time": "2025-02-27T19:30:59.313114",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "EcCL1F4eSVuZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:19.351211Z",
          "iopub.execute_input": "2025-02-28T17:58:19.35152Z",
          "iopub.status.idle": "2025-02-28T17:58:19.395524Z",
          "shell.execute_reply.started": "2025-02-28T17:58:19.351488Z",
          "shell.execute_reply": "2025-02-28T17:58:19.394727Z"
        },
        "papermill": {
          "duration": 0.039506,
          "end_time": "2025-02-27T19:30:59.428294",
          "exception": false,
          "start_time": "2025-02-27T19:30:59.388788",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "L97VDw9QSVua"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATA_PATH + 'faces_metadata.csv')\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:19.39637Z",
          "iopub.execute_input": "2025-02-28T17:58:19.396649Z",
          "iopub.status.idle": "2025-02-28T17:58:19.44713Z",
          "shell.execute_reply.started": "2025-02-28T17:58:19.396622Z",
          "shell.execute_reply": "2025-02-28T17:58:19.446448Z"
        },
        "papermill": {
          "duration": 0.061463,
          "end_time": "2025-02-27T19:30:59.499453",
          "exception": false,
          "start_time": "2025-02-27T19:30:59.43799",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "hNmro4KiSVuc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/input/"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:19.447881Z",
          "iopub.execute_input": "2025-02-28T17:58:19.448115Z",
          "iopub.status.idle": "2025-02-28T17:58:19.581165Z",
          "shell.execute_reply.started": "2025-02-28T17:58:19.448096Z",
          "shell.execute_reply": "2025-02-28T17:58:19.580384Z"
        },
        "papermill": {
          "duration": 0.143244,
          "end_time": "2025-02-27T19:30:59.652499",
          "exception": false,
          "start_time": "2025-02-27T19:30:59.509255",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "CvfsK-3jSVud"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_path(path: str) -> str:\n",
        "    for i in range(10):\n",
        "        path = path.replace(f'{i:02}', str(i))\n",
        "    return path\n",
        "\n",
        "\n",
        "def process_file_paths(df: pd.DataFrame) -> List[Tuple[str, str]]:\n",
        "    result: List[Tuple[str, str]] = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        file_name = row['file_path']\n",
        "\n",
        "        file_path = file_name\n",
        "\n",
        "        result.append((DATA_PATH + file_path, row['label']))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_video_info(video_path: str) -> Union[Tuple[int, float], Tuple[None, None]]:\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Не вдалося відкрити файл: {video_path}\")\n",
        "        return None, None\n",
        "\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    cap.release()\n",
        "\n",
        "    return frame_count, fps"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:19.582115Z",
          "iopub.execute_input": "2025-02-28T17:58:19.582437Z",
          "iopub.status.idle": "2025-02-28T17:58:19.589155Z",
          "shell.execute_reply.started": "2025-02-28T17:58:19.582404Z",
          "shell.execute_reply": "2025-02-28T17:58:19.5883Z"
        },
        "papermill": {
          "duration": 0.019598,
          "end_time": "2025-02-27T19:30:59.682153",
          "exception": false,
          "start_time": "2025-02-27T19:30:59.662555",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "dBE5GxAWSVue"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "video_stats = []\n",
        "result = process_file_paths(df)\n",
        "\n",
        "for video_path, label in result:\n",
        "    frame_count, fps = get_video_info(video_path)\n",
        "    if frame_count is not None and fps is not None:\n",
        "        video_stats.append({\n",
        "            'file_path': video_path,\n",
        "            'label': label,\n",
        "            'frames': frame_count,\n",
        "            'fps': fps\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(video_stats)\n",
        "\n",
        "stats_fps = df['fps'].describe()\n",
        "stats_frames = df['frames'].describe()\n",
        "\n",
        "print(\"FPS статистика:\")\n",
        "print(stats_fps)\n",
        "\n",
        "print(\"\\nКількість кадрів статистика:\")\n",
        "print(stats_frames)\n",
        "#df = df[df['fps'] >= 28]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:58:19.590135Z",
          "iopub.execute_input": "2025-02-28T17:58:19.590437Z",
          "iopub.status.idle": "2025-02-28T17:59:17.047299Z",
          "shell.execute_reply.started": "2025-02-28T17:58:19.590401Z",
          "shell.execute_reply": "2025-02-28T17:59:17.046585Z"
        },
        "papermill": {
          "duration": 62.264545,
          "end_time": "2025-02-27T19:32:01.956506",
          "exception": false,
          "start_time": "2025-02-27T19:30:59.691961",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "4iFsCC0JSVug"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "files_to_remove_unique = set(['avjwhrqbwl_0', 'bpqrwvichd_0', 'cctrhqvein_0', 'eupisnxhsb_0', 'gerhijzwvq_0', 'katmliewya_0', 'onoowfeded_0',\n",
        "                  'pydbvfkslp_0', 'qqisdvvgfi_0', 'sclvdumbkh_0', 'snphlfsrmr_0', 'spxqkpmopb_0', 'vugbaeziku_0', 'vvtcvjvkqx_0',\n",
        "                   'xuoqfchsfj_0', 'zdkyyawcwe_0', 'mshechsves_0', 'ejwvqbeyef_0', 'pqbyjmgmrk_0', 'drmtykanjz_0', 'fktxniwzxe_0',\n",
        "                   'iynuflmhau_0', 'kligyzlcuk_0', 'kifzxbsnku_0', 'kifzxbsnku_0', 'euarbrmuzs_0', 'fodhjwybqm_0', 'pbpgyiimwt_0',\n",
        "                   'qmqfqyqmfx_0', 'thmwcolqan_0', 'xhwacojjdg_0', 'xkwjjjkcam_0', 'zktuaqrqqv_0', 'cioizeilvz_0', 'cotvlcroov_0',\n",
        "                   'tuxbzsrszr_0', 'ynpqkrmuap_0', 'gomxkjifiu_0', 'ukrckkvaqi_0', 'vlcbaytswm_0', 'wmobvmntzu_0', 'ydqeopjemz_0',\n",
        "                   'cxfbhgmuyu_0', 'hqqmtxvbjj_0', 'jaetnqgktl_0', 'yurtzoovou_0', 'hlcqjuwpsd_0', 'iarobzzslu_0', 'ailmasxkxb_0',\n",
        "                   'bbwrqfawrj_0', 'cefzoeryat_0', 'egcuyhyvsm_0', 'eqgipviesf_0', 'fwekcrqdak_0', 'giqncczwue_0', 'hslupphtel_0',\n",
        "                   'jmqmljznhv_0', 'lkbpavasad_0', 'osqruujwxd_0', 'pjibpowymk_0', 'ptchnzeeqc_0', 'sppyyoqaey_0', 'tohrqjyter_0',\n",
        "                   'xzcexrifxq_0', 'aahncigwte_0', 'fszexmwczt_0', 'fszexmwczt_0', 'lkgrqfcrps_0', 'cdgrttukjn_0', 'eclxonfxph_0',\n",
        "                   'eclxonfxph_0', 'gzbagbdubm_0', 'hhhvnhhqsc_0', 'junllgghcq_0', 'qyefejorlb_0'\n",
        "                  ])\n",
        "files_to_remove = list(files_to_remove_unique)\n",
        "#df = df[~df['file_path'].apply(lambda x: any(file in x for file in files_to_remove))]\n",
        "#df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.048137Z",
          "iopub.execute_input": "2025-02-28T17:59:17.048404Z",
          "iopub.status.idle": "2025-02-28T17:59:17.053849Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.048382Z",
          "shell.execute_reply": "2025-02-28T17:59:17.052844Z"
        },
        "papermill": {
          "duration": 0.016466,
          "end_time": "2025-02-27T19:32:01.982627",
          "exception": false,
          "start_time": "2025-02-27T19:32:01.966161",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "1LANlRc-SVuh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_list(df: pd.DataFrame) -> List[Tuple[str, str]]:\n",
        "    result: List[Tuple[str, str]] = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        file_name = row['file_path']\n",
        "\n",
        "        file_path = file_name\n",
        "\n",
        "        result.append((file_path, row['label']))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "result = df_to_list(df)\n",
        "#result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.054716Z",
          "iopub.execute_input": "2025-02-28T17:59:17.05501Z",
          "iopub.status.idle": "2025-02-28T17:59:17.290109Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.054982Z",
          "shell.execute_reply": "2025-02-28T17:59:17.289122Z"
        },
        "papermill": {
          "duration": 0.220557,
          "end_time": "2025-02-27T19:32:02.212586",
          "exception": false,
          "start_time": "2025-02-27T19:32:01.992029",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "9NFfgcDESVui"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "groups = defaultdict(list)\n",
        "for file_path, label in result:\n",
        "    base_name = os.path.basename(file_path).split('_')[0]\n",
        "    groups[base_name].append((file_path, label))\n",
        "\n",
        "single_element_groups = [group for group in groups.values() if len(group) == 1]\n",
        "\n",
        "#single_element_groups\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.290995Z",
          "iopub.execute_input": "2025-02-28T17:59:17.291274Z",
          "iopub.status.idle": "2025-02-28T17:59:17.302721Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.291252Z",
          "shell.execute_reply": "2025-02-28T17:59:17.301887Z"
        },
        "papermill": {
          "duration": 0.022055,
          "end_time": "2025-02-27T19:32:02.244692",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.222637",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "Ml6oBtHPSVui"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = [item for group in single_element_groups for item in group]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.306248Z",
          "iopub.execute_input": "2025-02-28T17:59:17.306494Z",
          "iopub.status.idle": "2025-02-28T17:59:17.325593Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.306475Z",
          "shell.execute_reply": "2025-02-28T17:59:17.324871Z"
        },
        "papermill": {
          "duration": 0.015247,
          "end_time": "2025-02-27T19:32:02.26974",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.254493",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "uz6B-qEZSVuj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#train_files"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.327648Z",
          "iopub.execute_input": "2025-02-28T17:59:17.327959Z",
          "iopub.status.idle": "2025-02-28T17:59:17.339173Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.327926Z",
          "shell.execute_reply": "2025-02-28T17:59:17.338373Z"
        },
        "papermill": {
          "duration": 0.014775,
          "end_time": "2025-02-27T19:32:02.294252",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.279477",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "_ifKVgZnSVuj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(train_files, columns=['video_path', 'label'])\n",
        "#real_videos = df[df['label'] == 'REAL']\n",
        "#fake_videos = df[df['label'] == 'FAKE']\n",
        "\n",
        "#min_samples = min(len(real_videos), len(fake_videos))\n",
        "\n",
        "#real_balanced = real_videos.sample(n=min_samples, random_state=42)\n",
        "#fake_balanced = fake_videos.sample(n=min_samples, random_state=42)\n",
        "\n",
        "#df = pd.concat([real_balanced, fake_balanced]).sample(frac=1, random_state=17)\n",
        "\n",
        "train_data = df[~df['video_path'].str.contains('dfdc_train_part_8|dfdc_train_part_7')]\n",
        "val_data = df[df['video_path'].str.contains('dfdc_train_part_8')]\n",
        "test_data = df[df['video_path'].str.contains('dfdc_train_part_7')]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.339958Z",
          "iopub.execute_input": "2025-02-28T17:59:17.340182Z",
          "iopub.status.idle": "2025-02-28T17:59:17.363463Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.340163Z",
          "shell.execute_reply": "2025-02-28T17:59:17.362798Z"
        },
        "papermill": {
          "duration": 0.024993,
          "end_time": "2025-02-27T19:32:02.32874",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.303747",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "M1C5OqlgSVuj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(11):\n",
        "    subset_df = df[df['video_path'].str.contains(f'dfdc_train_part_{i}')]\n",
        "    label_distribution = subset_df['label'].value_counts()\n",
        "    print(i)\n",
        "    print(label_distribution)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.364164Z",
          "iopub.execute_input": "2025-02-28T17:59:17.364356Z",
          "iopub.status.idle": "2025-02-28T17:59:17.408977Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.364339Z",
          "shell.execute_reply": "2025-02-28T17:59:17.408228Z"
        },
        "papermill": {
          "duration": 0.05839,
          "end_time": "2025-02-27T19:32:02.396701",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.338311",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "trusted": true,
        "id": "oXseACe3SVuk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data, test_data = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=17)\n",
        "\n",
        "print(\"Train set size:\", len(train_data))\n",
        "print(\"Val set size:\", len(val_data))\n",
        "print(\"Test set size:\", len(test_data))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.409943Z",
          "iopub.execute_input": "2025-02-28T17:59:17.410262Z",
          "iopub.status.idle": "2025-02-28T17:59:17.415064Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.41024Z",
          "shell.execute_reply": "2025-02-28T17:59:17.414164Z"
        },
        "papermill": {
          "duration": 0.01628,
          "end_time": "2025-02-27T19:32:02.423507",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.407227",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "p6VC2PCASVuk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.415916Z",
          "iopub.execute_input": "2025-02-28T17:59:17.416224Z",
          "iopub.status.idle": "2025-02-28T17:59:17.435943Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.416195Z",
          "shell.execute_reply": "2025-02-28T17:59:17.435319Z"
        },
        "papermill": {
          "duration": 0.019044,
          "end_time": "2025-02-27T19:32:02.452084",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.43304",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "pD7blLykSVuk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#real_videos = train_data[train_data['label'] == 'REAL']\n",
        "#fake_videos = train_data[train_data['label'] == 'FAKE']\n",
        "\n",
        "#min_samples = min(len(real_videos), len(fake_videos))\n",
        "\n",
        "#real_balanced = real_videos.sample(n=min_samples, random_state=42)\n",
        "#fake_balanced = fake_videos.sample(n=min_samples, random_state=42)\n",
        "\n",
        "#train_data = pd.concat([real_balanced, fake_balanced]).sample(frac=1, random_state=17)\n",
        "#train_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.436745Z",
          "iopub.execute_input": "2025-02-28T17:59:17.437055Z",
          "iopub.status.idle": "2025-02-28T17:59:17.449954Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.437006Z",
          "shell.execute_reply": "2025-02-28T17:59:17.448933Z"
        },
        "papermill": {
          "duration": 0.014349,
          "end_time": "2025-02-27T19:32:02.476273",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.461924",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "wG_vH8FASVuk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['label'].hist()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.450917Z",
          "iopub.execute_input": "2025-02-28T17:59:17.451225Z",
          "iopub.status.idle": "2025-02-28T17:59:17.722339Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.451196Z",
          "shell.execute_reply": "2025-02-28T17:59:17.721465Z"
        },
        "papermill": {
          "duration": 0.309135,
          "end_time": "2025-02-27T19:32:02.795151",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.486016",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "7T0KqoAgSVuk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_data['label'].hist()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.723251Z",
          "iopub.execute_input": "2025-02-28T17:59:17.723578Z",
          "iopub.status.idle": "2025-02-28T17:59:17.847709Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.723546Z",
          "shell.execute_reply": "2025-02-28T17:59:17.846751Z"
        },
        "papermill": {
          "duration": 0.132115,
          "end_time": "2025-02-27T19:32:02.937712",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.805597",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "OYiX4QJZSVuk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['label'].hist()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.84845Z",
          "iopub.execute_input": "2025-02-28T17:59:17.848723Z",
          "iopub.status.idle": "2025-02-28T17:59:17.980941Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.848699Z",
          "shell.execute_reply": "2025-02-28T17:59:17.979866Z"
        },
        "papermill": {
          "duration": 0.133679,
          "end_time": "2025-02-27T19:32:03.082609",
          "exception": false,
          "start_time": "2025-02-27T19:32:02.94893",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "-XcZVBp5SVul"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train set size:\", len(train_data))\n",
        "print(\"Val set size:\", len(val_data))\n",
        "print(\"Test set size:\", len(test_data))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.981952Z",
          "iopub.execute_input": "2025-02-28T17:59:17.982291Z",
          "iopub.status.idle": "2025-02-28T17:59:17.988127Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.982258Z",
          "shell.execute_reply": "2025-02-28T17:59:17.987277Z"
        },
        "papermill": {
          "duration": 0.018049,
          "end_time": "2025-02-27T19:32:03.111865",
          "exception": false,
          "start_time": "2025-02-27T19:32:03.093816",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "sgtqrTjKSVul"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv(\"train_dataset.csv\", index=False)\n",
        "val_data.to_csv(\"val_dataset.csv\", index=False)\n",
        "test_data.to_csv(\"test_dataset.csv\", index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:17.989062Z",
          "iopub.execute_input": "2025-02-28T17:59:17.989407Z",
          "iopub.status.idle": "2025-02-28T17:59:18.023985Z",
          "shell.execute_reply.started": "2025-02-28T17:59:17.989373Z",
          "shell.execute_reply": "2025-02-28T17:59:18.023273Z"
        },
        "papermill": {
          "duration": 0.033187,
          "end_time": "2025-02-27T19:32:03.155871",
          "exception": false,
          "start_time": "2025-02-27T19:32:03.122684",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "0KHKLh8bSVul"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_json_from_csv(input_csv: str, output_json: str) -> None:\n",
        "    df = pd.read_csv(input_csv)\n",
        "    result: Dict[str, str] = {}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        file_path = row['video_path']\n",
        "        label = row['label']\n",
        "\n",
        "        result[file_path] = {'label': label}\n",
        "\n",
        "    with open(output_json, 'w') as json_file:\n",
        "        json.dump(result, json_file, indent=4)\n",
        "\n",
        "\n",
        "create_json_from_csv('train_dataset.csv', 'output_balenced_train.json')\n",
        "create_json_from_csv('val_dataset.csv', 'output_balenced_val.json')\n",
        "create_json_from_csv('test_dataset.csv', 'output_balenced_test.json')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:18.024802Z",
          "iopub.execute_input": "2025-02-28T17:59:18.025002Z",
          "iopub.status.idle": "2025-02-28T17:59:18.291592Z",
          "shell.execute_reply.started": "2025-02-28T17:59:18.024985Z",
          "shell.execute_reply": "2025-02-28T17:59:18.290923Z"
        },
        "papermill": {
          "duration": 0.262299,
          "end_time": "2025-02-27T19:32:03.429022",
          "exception": false,
          "start_time": "2025-02-27T19:32:03.166723",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "4TMlZJLnSVul"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open('output_balenced_train.json', 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "label_counts = Counter()\n",
        "\n",
        "for item in data.values():\n",
        "    label_counts[item['label']] += 1\n",
        "\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"Label: {label}, Count: {count}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:18.292311Z",
          "iopub.execute_input": "2025-02-28T17:59:18.292508Z",
          "iopub.status.idle": "2025-02-28T17:59:18.302672Z",
          "shell.execute_reply.started": "2025-02-28T17:59:18.292491Z",
          "shell.execute_reply": "2025-02-28T17:59:18.30196Z"
        },
        "papermill": {
          "duration": 0.021785,
          "end_time": "2025-02-27T19:32:03.462337",
          "exception": false,
          "start_time": "2025-02-27T19:32:03.440552",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "QsUtx9R2SVul"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class VideoDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, n_frames: int, df_path: str, device, cache_folder: str, image_size=(224, 224), transform=None):\n",
        "\n",
        "        self.n_frames = n_frames\n",
        "        self.videos = []\n",
        "        self.device = device if device is not None else torch.device(\"cpu\")\n",
        "        self.cache_folder = cache_folder\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        self.detector = MTCNN(device=device, post_process=False)\n",
        "\n",
        "        with open(df_path) as f:\n",
        "            videos = json.load(f)\n",
        "            videos = [(video, metadata) for (video, metadata) in videos.items()]\n",
        "            self.videos += videos\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        video, metadata = self.videos[n]\n",
        "        video_id = os.path.splitext(os.path.basename(video))[0]\n",
        "        cap = cv2.VideoCapture(video)\n",
        "\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Загальна кількість кадрів у відео\n",
        "        start_frame = random.randint(0, max(0, total_frames - self.n_frames))  # Випадковий стартовий кадр\n",
        "\n",
        "        # Перемотка до стартового кадру\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "        frames = []\n",
        "\n",
        "        for _ in range(self.n_frames):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            resize = (self.image_size[0], self.image_size[1])\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0\n",
        "            frames.append(frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        frames = torch.stack(frames).to(self.device)\n",
        "\n",
        "        if self.transform:\n",
        "            frames = self.transform(frames)\n",
        "\n",
        "        label = 0.0\n",
        "        if metadata['label'] == 'FAKE':\n",
        "            label = 1.0\n",
        "\n",
        "        return frames, torch.FloatTensor([label]).to(self.device)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.videos)\n",
        "\n",
        "\n",
        "class SameAugmentation:\n",
        "    def __init__(self, augmentations):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            augmentations (callable): Трансформації, що застосовуються до всіх кадрів.\n",
        "        \"\"\"\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "    def __call__(self, frames):\n",
        "        # Ініціалізуємо однакове перетворення\n",
        "        seed = torch.randint(0, 2**32, (1,)).item()\n",
        "\n",
        "        # Застосовуємо однакові трансформації до всіх кадрів\n",
        "        augmented_frames = []\n",
        "        for frame in frames:\n",
        "            torch.manual_seed(seed)  # Встановлюємо однаковий seed\n",
        "            augmented_frames.append(self.augmentations(frame))\n",
        "\n",
        "        return torch.stack(augmented_frames)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:18.303333Z",
          "iopub.execute_input": "2025-02-28T17:59:18.303531Z",
          "iopub.status.idle": "2025-02-28T17:59:18.317762Z",
          "shell.execute_reply.started": "2025-02-28T17:59:18.303514Z",
          "shell.execute_reply": "2025-02-28T17:59:18.317062Z"
        },
        "papermill": {
          "duration": 0.022104,
          "end_time": "2025-02-27T19:32:03.495293",
          "exception": false,
          "start_time": "2025-02-27T19:32:03.473189",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "HiUH5dXASVul"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_data():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    transfor = SameAugmentation(\n",
        "        transforms.Compose([\n",
        "            # Горизонтальне відображення\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            # Легке афінне перетворення\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "            # Легкий поворот\n",
        "            transforms.RandomRotation(degrees=5, fill=0),\n",
        "            # Розмиття для імітації відео низької якості\n",
        "            transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),\n",
        "            # Колірні зміни (яскравість, контраст)\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
        "            # Перетворення в сірий для певного шуму\n",
        "            transforms.RandomGrayscale(p=0.1),\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    dataset = VideoDataset(20, 'output_balenced_train.json', device, 'cache', (224, 224), transfor)\n",
        "\n",
        "    for i, batch in enumerate(dataset):\n",
        "        frames, label = batch\n",
        "        print(f\"Label: {label}\")\n",
        "\n",
        "        if frames.size() != torch.Size([20, 3, 224, 224]):\n",
        "            print(f\"Unexpected frame size: {frames.size()}\")\n",
        "\n",
        "        fig, axes = plt.subplots(1, 20, figsize=(20, 10))\n",
        "\n",
        "        for j in range(20):\n",
        "            ax = axes[j]\n",
        "            frame = frames[j].cpu().permute(1, 2, 0).numpy()\n",
        "            ax.imshow(frame)\n",
        "            ax.set_title(f\"Frame {j+1}\")\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "        break\n",
        "\n",
        "\n",
        "test_train_data()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:18.318641Z",
          "iopub.execute_input": "2025-02-28T17:59:18.319102Z",
          "iopub.status.idle": "2025-02-28T17:59:20.598901Z",
          "shell.execute_reply.started": "2025-02-28T17:59:18.319056Z",
          "shell.execute_reply": "2025-02-28T17:59:20.594563Z"
        },
        "papermill": {
          "duration": 2.101851,
          "end_time": "2025-02-27T19:32:05.607988",
          "exception": false,
          "start_time": "2025-02-27T19:32:03.506137",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "98a_s6C0SVum"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def test_test_data():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dataset = VideoDataset(20, 'output_balenced_test.json', device, 'cache', (224, 224), None)\n",
        "\n",
        "    for i, batch in enumerate(dataset):\n",
        "        frames, label = batch\n",
        "        print(f\"Label: {label}\")\n",
        "\n",
        "        if frames.size() != torch.Size([20, 3, 224, 224]):\n",
        "            print(f\"Unexpected frame size: {frames.size()}\")\n",
        "\n",
        "        fig, axes = plt.subplots(1, 20, figsize=(20, 10))\n",
        "\n",
        "        for j in range(20):\n",
        "            ax = axes[j]\n",
        "            frame = frames[j].cpu().permute(1, 2, 0).numpy()\n",
        "            ax.imshow(frame)\n",
        "            ax.set_title(f\"Frame {j+1}\")\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "        break\n",
        "\n",
        "\n",
        "test_test_data()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:20.599948Z",
          "iopub.execute_input": "2025-02-28T17:59:20.600318Z",
          "iopub.status.idle": "2025-02-28T17:59:21.841424Z",
          "shell.execute_reply.started": "2025-02-28T17:59:20.600284Z",
          "shell.execute_reply": "2025-02-28T17:59:21.840629Z"
        },
        "papermill": {
          "duration": 1.195546,
          "end_time": "2025-02-27T19:32:06.81922",
          "exception": false,
          "start_time": "2025-02-27T19:32:05.623674",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "qnfNZjkgSVun"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(conf_matrix, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {title}')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_training_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "\n",
        "    minposs = val_losses.index(min(val_losses))\n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss per Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy per Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix_final(all_labels, all_preds, title):\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {title}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:21.916509Z",
          "iopub.execute_input": "2025-02-28T17:59:21.916802Z",
          "iopub.status.idle": "2025-02-28T17:59:21.933821Z",
          "shell.execute_reply.started": "2025-02-28T17:59:21.916776Z",
          "shell.execute_reply": "2025-02-28T17:59:21.933117Z"
        },
        "papermill": {
          "duration": 0.026655,
          "end_time": "2025-02-27T19:32:07.063748",
          "exception": false,
          "start_time": "2025-02-27T19:32:07.037093",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "qPXnCfF-SVur"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_val_loss = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if np.isnan(val_loss):\n",
        "            self.trace_func(\"Validation loss is NaN. Ignoring this epoch.\")\n",
        "            return\n",
        "\n",
        "        if self.best_val_loss is None:\n",
        "            self.best_val_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif val_loss < self.best_val_loss - self.delta:\n",
        "            self.best_val_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decreases.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:21.934621Z",
          "iopub.execute_input": "2025-02-28T17:59:21.93489Z",
          "iopub.status.idle": "2025-02-28T17:59:21.960539Z",
          "shell.execute_reply.started": "2025-02-28T17:59:21.93486Z",
          "shell.execute_reply": "2025-02-28T17:59:21.959711Z"
        },
        "papermill": {
          "duration": 0.026328,
          "end_time": "2025-02-27T19:32:07.108323",
          "exception": false,
          "start_time": "2025-02-27T19:32:07.081995",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "gWp1rVAUSVur"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, hparms: dict[str, Union[int, float]], path_train: str, path_test: str, size: tuple[int], device, name: str, checkpoint_path: str = None):\n",
        "    batch_size = hparms['batch_size']\n",
        "    num_epochs = hparms['num_epochs']\n",
        "    n_frames = hparms['n_frames']\n",
        "    lr = hparms['lr']\n",
        "\n",
        "    gamma = hparms['gamma']\n",
        "    milestones = hparms['milestones']\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    early_stopping = EarlyStopping(patience=15, verbose=True, delta=0.0001, path=f'early_stopping_{name}_lstm_checkpoint.pt')\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "\n",
        "    transfor_train = SameAugmentation(\n",
        "        transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "            transforms.RandomRotation(degrees=5, fill=0),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
        "            transforms.RandomGrayscale(p=0.1),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    transfor = SameAugmentation(\n",
        "        transforms.Compose([\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    train_dataset = VideoDataset(n_frames, path_train, device, 'cache', size, transfor_train)\n",
        "    test_dataset = VideoDataset(n_frames, path_test, device, 'cache', size, transfor)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    start_time = datetime.datetime.now()\n",
        "    print(f'Start time: {start_time}, using device: {device}')\n",
        "\n",
        "    best_loss = np.inf\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "    epoch_times = []\n",
        "\n",
        "    if checkpoint_path:\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        epoch_t_loss, epoch_v_loss = 0, 0\n",
        "        t_count, t_count_wrong = 0, 0\n",
        "        all_train_labels, all_train_preds = [], []\n",
        "        test_probs = []\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for video_data, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} Training\", leave=False):\n",
        "            video_data, labels = video_data.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(video_data)\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            epoch_t_loss += loss.item()\n",
        "            output = torch.sigmoid(output).round()\n",
        "            n_wrong = (labels - output).abs().sum().item()\n",
        "            t_count_wrong += n_wrong\n",
        "            t_count += labels.shape[0]\n",
        "\n",
        "            all_train_labels.extend(labels.detach().cpu().numpy())\n",
        "            all_train_preds.extend(output.detach().cpu().numpy())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss = epoch_t_loss / len(train_loader)\n",
        "        train_accuracy = (t_count - t_count_wrong) / t_count\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        all_val_labels, all_val_preds = [], []\n",
        "        with torch.no_grad():\n",
        "            for video_data, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
        "                video_data, labels = video_data.to(device), labels.to(device)\n",
        "\n",
        "                output = model(video_data)\n",
        "                output_probs = torch.sigmoid(output)\n",
        "                test_probs.extend(output_probs.cpu().numpy())\n",
        "\n",
        "                loss = criterion(output, labels)\n",
        "                epoch_v_loss += loss.item()\n",
        "\n",
        "                output = torch.sigmoid(output).round()\n",
        "                all_val_labels.extend(labels.cpu().numpy())\n",
        "                all_val_preds.extend(output.cpu().numpy())\n",
        "\n",
        "        val_loss = epoch_v_loss / len(val_loader)\n",
        "        val_accuracy = np.sum(np.array(all_val_labels) == np.array(all_val_preds)) / len(all_val_labels)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        epoch_exec_time = time.time() - epoch_start_time\n",
        "        epoch_times.append(epoch_exec_time)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} - Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}')\n",
        "        print(f'Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}, Time: {epoch_exec_time:.2f}s')\n",
        "        val_auc = roc_auc_score(all_val_labels, test_probs)\n",
        "        print(f'Validation AUC: {val_auc}')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        torch.save({\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                     'optimizer_state_dict': optimizer.state_dict(),\n",
        "                     'scheduler_state_dict': scheduler.state_dict(),\n",
        "                      'epoch': epoch + 1\n",
        "                      }, f'best_{name}_lstm_checkpoint_epoch_{epoch + 1}.pt'\n",
        "        )\n",
        "\n",
        "        early_stopping(val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    print(f'Training completed in: {str(datetime.datetime.now() - start_time)}')\n",
        "\n",
        "    plot_training_metrics(train_losses, val_losses, train_accuracies, val_accuracies)\n",
        "\n",
        "    print(\"Train Classification Report:\")\n",
        "    print(classification_report(all_train_labels, all_train_preds))\n",
        "    plot_confusion_matrix_final(all_train_labels, all_train_preds, 'Train')\n",
        "\n",
        "    print(\"Validation Classification Report:\")\n",
        "    print(classification_report(all_val_labels, all_val_preds))\n",
        "    plot_confusion_matrix_final(all_val_labels, all_val_preds, 'Validation')\n",
        "    val_auc = roc_auc_score(all_val_labels, test_probs)\n",
        "    print(f'Validation AUC: {val_auc}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:22.095008Z",
          "iopub.execute_input": "2025-02-28T17:59:22.095235Z",
          "iopub.status.idle": "2025-02-28T17:59:22.112909Z",
          "shell.execute_reply.started": "2025-02-28T17:59:22.095217Z",
          "shell.execute_reply": "2025-02-28T17:59:22.112245Z"
        },
        "papermill": {
          "duration": 0.035948,
          "end_time": "2025-02-27T19:32:07.544273",
          "exception": false,
          "start_time": "2025-02-27T19:32:07.508325",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "u17F0CYPSVu0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class B3LSTMClassifier(nn.Module):\n",
        "    def __init__(self, n_linear_hidden, lstm_hidden_dim, num_lstm_layers,\n",
        "                 dropout, bidirectional, freeze):\n",
        "        super(B3LSTMClassifier, self).__init__()\n",
        "\n",
        "        self.cnn = models.efficientnet_b3(pretrained=True)\n",
        "        self.feature_output_size = 1536\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            *list(self.cnn.children())[:-1],\n",
        "        )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.feature_output_size,\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=num_lstm_layers,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        lstm_output_dim = lstm_hidden_dim * (2 if bidirectional else 1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_output_dim, lstm_hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(lstm_hidden_dim // 2, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, vid_frames):\n",
        "        batch_size, num_frames, channels, height, width = vid_frames.shape\n",
        "        vid_frames = vid_frames.view(batch_size * num_frames, channels, height, width)\n",
        "\n",
        "        vid_features = self.feature_extractor(vid_frames)  # (batch_size*num_frames, feature_output_size, 1, 1)\n",
        "        vid_features = vid_features.view(batch_size, num_frames, -1)  # (batch_size, num_frames, feature_output_size)\n",
        "\n",
        "        lstm_out, _ = self.lstm(vid_features)  # (batch_size, num_frames, lstm_hidden_dim * num_directions)\n",
        "\n",
        "        output = self.classifier(lstm_out[:, -1, :])  # (batch_size, 1)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:22.151307Z",
          "iopub.execute_input": "2025-02-28T17:59:22.151582Z",
          "iopub.status.idle": "2025-02-28T17:59:22.169821Z",
          "shell.execute_reply.started": "2025-02-28T17:59:22.151555Z",
          "shell.execute_reply": "2025-02-28T17:59:22.168968Z"
        },
        "papermill": {
          "duration": 0.033157,
          "end_time": "2025-02-27T19:32:07.698607",
          "exception": false,
          "start_time": "2025-02-27T19:32:07.66545",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "tgR3dxoTSVu1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters_1: dict[str: Union[int, float, list]] = {\n",
        "    'n_linear_hidden': 64,\n",
        "    'lstm_hidden_dim': 32,\n",
        "    'num_lstm_layers': 2,\n",
        "    'dropout': 0.4,\n",
        "    'bidirectional': False,\n",
        "    'freeze': False,\n",
        "    'n_frames': 20,\n",
        "    'batch_size': 4,\n",
        "    'lr': 0.00001,\n",
        "    'num_epochs': 25,\n",
        "    'gamma': 0.1,\n",
        "    'milestones': [32, 64]\n",
        "}\n",
        "\n",
        "models_to_train = [\n",
        "    (B3LSTMClassifier, 'B3LSTMClassifier20x224', (224, 224), hyperparameters_1)\n",
        "]\n",
        "\n",
        "for model_type, name, size, hyperparameters in models_to_train:\n",
        "    model = model_type(\n",
        "        n_linear_hidden=hyperparameters['n_linear_hidden'],\n",
        "        lstm_hidden_dim=hyperparameters['lstm_hidden_dim'],\n",
        "        num_lstm_layers=hyperparameters['num_lstm_layers'],\n",
        "        dropout=hyperparameters['dropout'],\n",
        "        bidirectional=hyperparameters['bidirectional'],\n",
        "        freeze=hyperparameters['freeze']\n",
        "    )\n",
        "\n",
        "    print(f'Training {name} model:')\n",
        "    print('Hyperparameters', hyperparameters)\n",
        "    trainable_layers = [name for name, param in model.named_parameters() if param.requires_grad]\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    train_model(model, hyperparameters, 'output_balenced_train.json', 'output_balenced_val.json', size, device, name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-28T17:59:22.170692Z",
          "iopub.execute_input": "2025-02-28T17:59:22.170968Z",
          "execution_failed": "2025-02-28T18:01:14.319Z"
        },
        "papermill": {
          "duration": 38546.855071,
          "end_time": "2025-02-28T06:14:34.571869",
          "exception": false,
          "start_time": "2025-02-27T19:32:07.716798",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "-W42qgvqSVu2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model: nn.Module, data_path: str, n_frames: int, size: Tuple[int, int]):\n",
        "    batch_size = 1\n",
        "    epoch_v_loss = 0\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    transfor = SameAugmentation(\n",
        "        transforms.Compose([\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    test_dataset = VideoDataset(n_frames, data_path, device, 'cache', size, transfor)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model.eval()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    all_val_labels, all_val_preds = [], []\n",
        "    test_probs = []\n",
        "    with torch.no_grad():\n",
        "        for video_data, labels in tqdm(test_loader, desc=\"Test\", leave=False):\n",
        "            video_data, labels = video_data.to(device), labels.to(device)\n",
        "\n",
        "            output = model(video_data)\n",
        "            output_probs = torch.sigmoid(output)\n",
        "            test_probs.extend(output_probs.cpu().numpy())\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            epoch_v_loss += loss.item()\n",
        "\n",
        "            output = torch.sigmoid(output).round()\n",
        "            all_val_labels.extend(labels.cpu().numpy())\n",
        "            all_val_preds.extend(output.cpu().numpy())\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    val_loss = epoch_v_loss / len(test_loader)\n",
        "    val_accuracy = np.sum(np.array(all_val_labels) == np.array(all_val_preds)) / len(all_val_labels)\n",
        "\n",
        "    print(f'Test loss: {val_loss:.4f}, Test accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    print(\"Test Classification Report:\")\n",
        "    print(classification_report(all_val_labels, all_val_preds))\n",
        "    plot_confusion_matrix_final(all_val_labels, all_val_preds, 'Test')\n",
        "    val_auc = roc_auc_score(all_val_labels, test_probs)\n",
        "    print(f'Test AUC: {val_auc}')"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-02-28T18:01:14.32Z"
        },
        "papermill": {
          "duration": 2.958314,
          "end_time": "2025-02-28T06:14:40.487817",
          "exception": false,
          "start_time": "2025-02-28T06:14:37.529503",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "BXUKGbiJSVu2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model, 'output_balenced_test.json', 20, (224, 224))\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-02-28T18:01:14.32Z"
        },
        "papermill": {
          "duration": 194.972704,
          "end_time": "2025-02-28T06:17:58.360859",
          "exception": false,
          "start_time": "2025-02-28T06:14:43.388155",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "-fU5uTzcSVu2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/kaggle/working/early_stopping_B3LSTMClassifier20x224_lstm_checkpoint.pt'\n",
        "\n",
        "model = ResNetLSTMClassifier(\n",
        "    n_linear_hidden=hyperparameters_1['n_linear_hidden'],\n",
        "    lstm_hidden_dim=hyperparameters_1['lstm_hidden_dim'],\n",
        "    num_lstm_layers=hyperparameters_1['num_lstm_layers'],\n",
        "    dropout=hyperparameters_1['dropout'],\n",
        "    bidirectional=hyperparameters_1['bidirectional'],\n",
        "    freeze=hyperparameters_1['freeze']\n",
        ")\n",
        "checkpoint = torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "test_model(model, 'output_balenced_test.json', 20, (224, 224))"
      ],
      "metadata": {
        "execution": {
          "execution_failed": "2025-02-28T18:01:14.32Z"
        },
        "papermill": {
          "duration": 198.009509,
          "end_time": "2025-02-28T06:21:19.312242",
          "exception": false,
          "start_time": "2025-02-28T06:18:01.302733",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "dDqvH4WKSVu2"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}